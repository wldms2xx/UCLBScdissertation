{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation \n",
    "\n",
    "\n",
    "# Define feature sets\n",
    "X_clinical = df[clinical_vars]                  # Clinical variables only\n",
    "X_overlap = df[[overlap_var]]                    # Overlap variable only\n",
    "X_clinical_overlap = df[clinical_vars + [overlap_var]]  # Clinical + Overlap combined\n",
    "y = df[target_var]\n",
    "\n",
    "# Define cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store AUC scores and ROC curve points\n",
    "clinical_auc = []\n",
    "overlap_auc = []\n",
    "clinical_overlap_auc = []\n",
    "\n",
    "tpr_clinical_list = []\n",
    "tpr_overlap_list = []\n",
    "tpr_clinical_overlap_list = []\n",
    "\n",
    "fpr_clinical_list = []\n",
    "fpr_overlap_list = []\n",
    "fpr_clinical_overlap_list = []\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Perform cross-validation\n",
    "y_pred=np.zeros((len(y),3))\n",
    "\n",
    "model='xg'\n",
    "\n",
    "for train_idx, test_idx in cv.split(X_clinical, y):\n",
    "    X_train_clinical, X_test_clinical = X_clinical.iloc[train_idx], X_clinical.iloc[test_idx]\n",
    "    X_train_overlap, X_test_overlap = X_overlap.iloc[train_idx], X_overlap.iloc[test_idx]\n",
    "    X_train_clinical_overlap, X_test_clinical_overlap = X_clinical_overlap.iloc[train_idx], X_clinical_overlap.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Train logistic regression models\n",
    "    if 'forest' in model:\n",
    "        model_clinical = RandomForestClassifier(random_state=42)\n",
    "        model_overlap = RandomForestClassifier(random_state=42)\n",
    "        model_clinical_overlap = RandomForestClassifier(random_state=42)\n",
    "    elif 'xg' in model:\n",
    "        model_clinical = XGBClassifier(base_score=0.5, booster='gbtree', gamma=0, \n",
    "                                    max_depth=1, eval_metric='error', subsample=0.9,\n",
    "                                    objective='binary:logistic', use_label_encoder=False)\n",
    "        model_overlap = XGBClassifier(base_score=0.5, booster='gbtree', gamma=0, \n",
    "                                    max_depth=1, eval_metric='error', subsample=0.9,\n",
    "                                    objective='binary:logistic', use_label_encoder=False)\n",
    "        model_clinical_overlap = XGBClassifier(base_score=0.5, booster='gbtree', gamma=0, \n",
    "                                            max_depth=1, eval_metric='error', subsample=0.9,\n",
    "                                            objective='binary:logistic', use_label_encoder=False)\n",
    "    elif 'logis' in model:\n",
    "        \n",
    "        model_clinical = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        model_overlap = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        model_clinical_overlap = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    else:\n",
    "        print(\"Model name not recognised\")\n",
    "        break\n",
    "\n",
    "    model_clinical.fit(X_train_clinical, y_train)\n",
    "    model_overlap.fit(X_train_overlap, y_train)\n",
    "    model_clinical_overlap.fit(X_train_clinical_overlap, y_train)\n",
    "    \n",
    "    # Get probabilities for ROC calculation\n",
    "    y_pred_clinical = model_clinical.predict_proba(X_test_clinical)[:, 1]\n",
    "    y_pred_overlap = model_overlap.predict_proba(X_test_overlap)[:, 1]\n",
    "    y_pred_clinical_overlap = model_clinical_overlap.predict_proba(X_test_clinical_overlap)[:, 1]\n",
    "    y_pred[test_idx,0] = y_pred_clinical\n",
    "    y_pred[test_idx,1] = y_pred_overlap\n",
    "    y_pred[test_idx,2] = y_pred_clinical_overlap\n",
    " \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr_clinical, tpr_clinical, _ = roc_curve(y, y_pred[:,0])\n",
    "fpr_overlap, tpr_overlap, _ = roc_curve(y, y_pred[:,1])\n",
    "fpr_clinical_overlap, tpr_clinical_overlap, _ = roc_curve(y, y_pred[:,2])\n",
    "clinical_auc = roc_auc_score(y, y_pred[:,0])\n",
    "overlap_auc = roc_auc_score(y, y_pred[:,1])\n",
    "clinical_overlap_auc = roc_auc_score(y, y_pred[:,2])\n",
    "\n",
    "plt.plot(fpr_clinical, tpr_clinical, label=f'Clinical only (AUC = {clinical_auc:.3f})', linestyle='--')\n",
    "plt.plot(fpr_overlap, tpr_overlap, label=f'Overlap only (AUC = {overlap_auc:.3f})', linestyle='-.')\n",
    "plt.plot(fpr_clinical_overlap, tpr_clinical_overlap, label=f'Clinical + Overlap (AUC = {clinical_overlap_auc:.3f})', linestyle='-')\n",
    "\n",
    "# Random classifier line\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random classifier (AUC = 0.5)\")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Cross-Validation Logistic Regression Model \")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUC distribution \n",
    "\n",
    "\n",
    "# Define model pairs for significance testing\n",
    "model_pairs = [\n",
    "    (\"Logistic_Clinical\", \"Logistic_Overlap\"),\n",
    "    (\"Logistic_Clinical\", \"Logistic_Combined\"),\n",
    "    (\"Logistic_Overlap\", \"Logistic_Combined\"),\n",
    "    (\"XGBoost_Clinical\", \"XGBoost_Overlap\"),\n",
    "    (\"XGBoost_Clinical\", \"XGBoost_Combined\"),\n",
    "    (\"XGBoost_Overlap\", \"XGBoost_Combined\"),\n",
    "    (\"XGBoost_Combined\", \"Logistic_Combined\")\n",
    "]\n",
    "\n",
    "# Store t-test results\n",
    "p_values = {}\n",
    "for model1, model2 in model_pairs:\n",
    "    _, p_value = ttest_rel(auc_scores[model1], auc_scores[model2])\n",
    "    p_values[(model1, model2)] = p_value\n",
    "\n",
    "# Define x positions\n",
    "x_labels = list(auc_scores.keys())\n",
    "x_pos = np.arange(len(x_labels))\n",
    "\n",
    "# Plot scatter and boxplots\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, key in enumerate(x_labels):\n",
    "    plt.scatter([x_pos[i]] * 10, auc_scores[key], label=key, alpha=0.7)\n",
    "    \n",
    "\n",
    "\n",
    "# Function to get significance stars\n",
    "def get_significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    elif p < 0.01:\n",
    "        return \"**\"\n",
    "    elif p < 0.05:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Annotate significance\n",
    "y_offset = 0.01  # Adjust for better visibility\n",
    "for (model1, model2), p_val in p_values.items():\n",
    "    if p_val < 0.05:  # Only show significant comparisons\n",
    "        x1, x2 = x_labels.index(model1), x_labels.index(model2)\n",
    "        y_max = max(max(auc_scores[model1]), max(auc_scores[model2])) + y_offset\n",
    "        \n",
    "        # Adjust the y_max position for the specific pair: \"XGBoost_Clinical\" vs. \"XGBoost_Combined\"\n",
    "        if model1 == \"XGBoost_Clinical\" and model2 == \"XGBoost_Combined\":\n",
    "            y_max += 0.03  # Shift upward by 0.05 to make space\n",
    "\n",
    "        plt.plot([x1, x1, x2, x2], [y_max, y_max + 0.01, y_max + 0.01, y_max], color='black', lw=1.5)\n",
    "        plt.text((x1 + x2) / 2, y_max + 0.015, get_significance_stars(p_val), ha='center', fontsize=12)\n",
    "x_labels = [\"clinical\",\"resection extent\",\"combined\",\"clinical\",\"resection extent\",\"combined\"]\n",
    "plt.text(1,0.43,'logistic regression',ha='center')\n",
    "plt.text(4,0.43,'XGboost',ha='center')\n",
    "# Final plot settings\n",
    "plt.xticks(x_pos, x_labels, rotation=30, ha=\"right\")\n",
    "plt.ylim(0.5, 0.85)\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
